{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "files=$(ls -1 1_raw | grep _R1 | cut -d'_' -f1)\n",
    "\n",
    "i=1\n",
    "for sample in $files\n",
    "do\n",
    "    mkdir 2_demultiplexed/${sample}/\n",
    "    python demultiplex.py \\\n",
    "    0_info/${sample}.tsv \\\n",
    "    1_raw/${sample}_S${i}_L001_R1_001.fastq.gz 1_raw/${sample}_S${i}_L001_R2_001.fastq.gz \\\n",
    "    2_demultiplexed/${sample}/\n",
    "    i=$((i+1))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir 3_qc\n",
    "mkdir 4_merged_fastq\n",
    "mkdir 5_merged_fasta\n",
    "\n",
    "libraries=$(ls -1 2_demultiplexed)\n",
    "for library in $libraries\n",
    "do\n",
    "    mkdir 3_qc/${library}/\n",
    "    mkdir 4_merged_fastq/${library}/\n",
    "    mkdir 5_merged_fasta/${library}/\n",
    "    files=$(ls -1 2_demultiplexed/${library} | grep -v invalid | grep .R1 | cut -d'.' -f1)\n",
    "    for sample in $files\n",
    "    do\n",
    "        fastp -i 2_demultiplexed/${library}/${sample}.R1.fastq -I 2_demultiplexed/${library}/${sample}.R2.fastq \\\n",
    "        -o 3_qc/${library}/${sample}.R1.fastq -O 3_qc/${library}/${sample}.R2.fastq \\\n",
    "        --unpaired1 3_qc/${library}/${sample}_unpaired.R1.fastq \\\n",
    "        --unpaired2 3_qc/${library}/${sample}_unpaired.R2.fastq \\\n",
    "        --failed_out 3_qc/${library}/${sample}_failed.fastq \\\n",
    "        -q 30 \\\n",
    "        --cut_tail \\\n",
    "        --trim_front1 20 \\\n",
    "        --trim_front2 20 \\\n",
    "        --max_len1 106 \\\n",
    "        --max_len2 106 \\\n",
    "        -l 90 \\\n",
    "        --merge \\\n",
    "        --overlap_len_require 90 \\\n",
    "        --correction \\\n",
    "        --merged_out 4_merged_fastq/${library}/${sample}.fastq \\\n",
    "        -w 6 \\\n",
    "        -h ./fastp_out/${sample}_fastp.html \\\n",
    "        -j ./fastp_out/${sample}_fastp.json\n",
    "        cat 3_qc/${library}/${sample}.R1.fastq >> 4_merged_fastq/${library}/${sample}.fastq\n",
    "        cat 3_qc/${library}/${sample}_unpaired.R1.fastq >> 4_merged_fastq/${library}/${sample}.fastq\n",
    "        seqkit fq2fa 4_merged_fastq/${library}/${sample}.fastq -o 5_merged_fasta/${library}/${sample}.fasta\n",
    "    done\n",
    "done\n",
    "\n",
    "#--correction \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRAKEN2 TIME!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir 6_kraken_outputs\n",
    "mkdir 7_kraken_reports\n",
    "\n",
    "libraries=$(ls -1 5_merged_fasta)\n",
    "\n",
    "for library in $libraries\n",
    "do\n",
    "    files=$(ls -1 5_merged_fasta/${library} | cut -d'.' -f1)\n",
    "    for sample in $files\n",
    "    do\n",
    "        kraken2 --db fish_kraken_02 \\\n",
    "        5_merged_fasta/${library}/${sample}.fasta \\\n",
    "        --use-names \\\n",
    "        --memory-mapping \\\n",
    "        --threads 6 \\\n",
    "        --report-zero-counts \\\n",
    "        --confidence 0.0 \\\n",
    "        --output 6_kraken_outputs/${sample}_output.tsv \\\n",
    "        --report 7_kraken_reports/${sample}_report.txt\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "kraken-biom 7_kraken_reports/*.txt --max F -o testing.biom\n",
    "biom convert -i testing.biom -o testing.tsv --to-tsv --header-key taxonomy\n",
    "\n",
    "echo -e '0' > total_reads.txt\n",
    "\n",
    "files=$(ls -1 7_kraken_reports/ | cut -d'.' -f1)\n",
    "for sample in $files\n",
    "do\n",
    "    a=$(awk '{s+=$3}END{print s}' 7_kraken_reports/${sample}.txt)\n",
    "    sed -i \"s/$/\\t$a/\" total_reads.txt\n",
    "done\n",
    "\n",
    "d=$(awk -F \";\" 'NR>2 {print substr($(NF-2),5)\"\\t\"substr($(NF-1),5)\"\\t\"substr($NF,5)}' testing.tsv | \\\n",
    "awk '{\n",
    "if ($3 ==\"\" && $2 ==\"\")\n",
    "    print $1;\n",
    "else if ($3 ==\"\" && $2 !=\"\")\n",
    "    print $2\"_spp.\";\n",
    "else\n",
    "    print $2\"_\"$3;\n",
    "}')\n",
    "\n",
    "awk 'NR<=2{print}' testing.tsv > testingx.tsv\n",
    "\n",
    "n=1\n",
    "for i in $d\n",
    "do\n",
    "n=$((n+1))\n",
    "awk -v i=$i -v n=$n 'NR==(1+n) {print i\"\\t\"$0}' testing.tsv | cut -f2 --complement >> testingx.tsv\n",
    "done\n",
    "\n",
    "a=$(cat total_reads.txt)\n",
    "echo $a >test.txt\n",
    "b=$(awk -F \"\\t\" 'NR>2{for (i=1;i<=NF;i++) sum[i]+=$i;}; END{for (i in sum) print sum[i]}' testing.tsv)\n",
    "echo $b >>test.txt\n",
    "c=$(awk '{ if (NR == 1) { for (i = 2; i <= NF; i++){ first_row[i] = $i} } else { for (i = 2; i <= NF-1; i++){ printf \"%s\\t\", first_row[i] - $i }; printf \"\\n\"}}' test.txt)\n",
    "\n",
    "echo unassigned $c u__unassigned > test.txt\n",
    "sed -i \"s/ /\\t/g\" test.txt\n",
    "\n",
    "awk '{print}' testingx.tsv > testing.tsv\n",
    "awk '{print}' test.txt >> testing.tsv\n",
    "\n",
    "rm test.txt\n",
    "rm total_reads.txt\n",
    "rm testingx.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "biom convert -i testing.tsv -o test2.biom --to-hdf5 --header-key taxonomy\n",
    "biom convert -i test2.biom -o test2.tsv --to-tsv --header-key taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!\n",
    "### you can go home now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "kraken2-build --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "awk -F'\\t' '$3 ~ /Capreolus/ {print $2}' 6_kraken_outputs/BLEL05_output.tsv > dodgy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "sequences=[]\n",
    "with open ('Rangifer.fasta','w') as fasta:\n",
    "    with open ('dodgy.txt','r') as txt:\n",
    "        for line in txt:\n",
    "            with open('5_merged_fasta/EA01/BLEL05.fasta','r') as fastin:\n",
    "                for record in SeqIO.parse(fastin,'fasta'):\n",
    "                    if line.strip() in record.name:\n",
    "                        sequences.append(record)\n",
    "    SeqIO.write(sequences,fasta,'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('dodgy.txt','r') as txt:\n",
    "    for line in txt:\n",
    "        print(line.strip())\n",
    "#list_d="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "libraries=$(ls -1 2_demultiplexed/)\n",
    "\n",
    "for library in $libraries\n",
    "do\n",
    "    files=$(ls -1 2_demultiplexed/${library} | cut -d'.' -f1)\n",
    "    for sample in $files\n",
    "    do\n",
    "        seqkit fq2fa 2_demultiplexed/${library}/${sample}.R1.fastq -o dirt/${library}/${sample}.fasta\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "libraries=$(ls -1 dirt/)\n",
    "\n",
    "for library in $libraries\n",
    "do\n",
    "    files=$(ls -1 dirt/${library} | cut -d'.' -f1)\n",
    "    for sample in $files\n",
    "    do\n",
    "        kraken2 --db ../database_stuff/fish_kraken \\\n",
    "        dirt/${library}/${sample}.fasta \\\n",
    "        --use-names \\\n",
    "        --report-zero-counts \\\n",
    "        --report terp/${sample}.txt\n",
    "        #--output 7_kraken_outputs\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "a=$(cat total_reads.txt)\n",
    "echo $a >test.txt\n",
    "b=$(awk -F \"\\t\" 'NR>2{for (i=1;i<=NF;i++) sum[i]+=$i;}; END{for (i in sum) print sum[i]}' testing.tsv)\n",
    "echo $b >>test.txt\n",
    "c=$(awk '{ if (NR == 1) { for (i = 2; i <= NF; i++){ first_row[i] = $i} } else { for (i = 2; i <= NF-1; i++){ printf \"%s\\t\", first_row[i] - $i }; printf \"\\n\"}}' test.txt)\n",
    "\n",
    "echo unassigned $c u__unassigned > test.txt\n",
    "sed -i \"s/ /\\t/g\" test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "d=$(awk -F \";\" 'NR>2 {print substr($(NF-2),5)\"\\t\"substr($(NF-1),5)\"\\t\"substr($NF,5)}' testing.tsv | \\\n",
    "awk '{\n",
    "if ($3 ==\"\" && $2 ==\"\")\n",
    "    print $1;\n",
    "else if ($3 ==\"\" && $2 !=\"\")\n",
    "    print $2\"_spp.\";\n",
    "else\n",
    "    print $2\"_\"$3;\n",
    "}')\n",
    "\n",
    "awk 'NR<=2{print}' testing.tsv > testingx.tsv\n",
    "\n",
    "n=1\n",
    "for i in $d\n",
    "do\n",
    "n=$((n+1))\n",
    "awk -v i=$i -v n=$n 'NR==(1+n) {print i\"\\t\"$0}' testing.tsv | cut -f2 --complement >> testingx.tsv\n",
    "done\n",
    "\n",
    "#awk 'NR<=2 {print}' testing.tsv > testingx.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2,4,6,8])\n",
    "b = np.array([1,3,5,7])\n",
    "c = a-b\n",
    "print (c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "files=$(set -- ls-1 6_kraken_reports/ $2)\n",
    "\n",
    "awk 'NR>1 {print $3\\t$6}'\n",
    "\n",
    "awk 'NR>2 {print $1}' testing.tsv > finaltest.txt\n",
    "\n",
    "taxid=$(cat finaltest.txt)\n",
    "for id in $taxid\n",
    "do\n",
    "     awk '$1 == $id {print $2}'\n",
    "done\n",
    " \n",
    "#awk 'NR>2 $1=\"[replace]\"' FS=, OFS=, testing.tsv > finaltest.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "files=$(ls -1 6_kraken_reports/)\n",
    "\n",
    "#l=\n",
    "\n",
    "awk '{print $5\"\\t\"$6}' 6_kraken_reports/$(set -- $files; echo -e $1)\n",
    "\n",
    "#files=$(ls -1 6_kraken_reports/)\n",
    "#echo -e $files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "#dictionary of taxid and scientific names\n",
    "\n",
    "lst1= glob.glob('test_data/output/*')\n",
    "with open(lst1[1],'r') as inp:\n",
    "    for line in inp:\n",
    "        print('%s\\t%s' %(line.split('\\t')[4],line.strip().split('\\t')[5].split('  ')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for sample in $files\n",
    "do\n",
    "    a=$(awk '{s+=$3}END{print s}' 6_kraken_reports/${sample}.txt)\n",
    "    sed -i \"s/$/\\t$a/\" total_reads.txt\n",
    "done\n",
    "\n",
    "awk '{s+=$3}END{print s}' 6_kraken_reports/BLEL01.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in $files\n",
    "do\n",
    "    a=$(awk 'NR==1{print $3}' test_data/output/${sample}.txt)\n",
    "    sed -i \"s/$/\\t$a/\" text.txt\n",
    "    #echo -e ${sample}'\\t' >> text.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_primer='ACTGGGATTAGATACCCC'\n",
    "r_primer='CTAGAGGAGCCTGTTCTA'\n",
    "\n",
    "len(r_primer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fastp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "files=$(ls -1 ../raw_data/EA01/ | grep .R1 | cut -d'.' -f1)\n",
    "for simple in $files\n",
    "do\n",
    "echo $simple\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVERSE COMPLIMENT DNA SEQUENCE\n",
    "\n",
    "revcom = lambda x: ''.join([{'A':'T','C':'G','G':'C','T':'A'}[B] for B in x][::-1])\n",
    "print (revcom('CTAGAGGAGCCTGTTCTA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('ACTATGCATGGCCATAAATTTTGATAAAAATATACAATTTTATCCGCCAGGGAACTTCAAGCATCAGCTTAAAACCCAAAGGACTTTGCCGTTCTTCTGTCCCACC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "touch_files()\n",
    "while True:\n",
    "    lines = []\n",
    "    line = f1.readline()\n",
    "    if line.strip() == \"\":\n",
    "        break\n",
    "    lines.append(line.strip())\n",
    "\n",
    "    for i in range(3):\n",
    "        lines.append(f1.readline().strip())\n",
    "\n",
    "    for i in range(4):\n",
    "        lines.append(f2.readline().strip())\n",
    "\n",
    "    temp = find_bcs(lines, sample_data, search_until)\n",
    "    if temp:\n",
    "        invalid_recs['R1'].extend(temp[:4])\n",
    "        invalid_recs['R2'].extend(temp[4:])\n",
    "    count+=1\n",
    "    if (count % 100000) == 1:\n",
    "        print(\"[\"+time.strftime(\"%c\")+\"] - %i read pairs processed\" %(count/2*2))\n",
    "        write_out(0)\n",
    "return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#files=$(ls -1 ../Fastq | grep _R1 | cut -d'_' -f1)\n",
    "files='EA01'\n",
    "i=1\n",
    "for sample in $files\n",
    "do\n",
    "    mkdir ../raw_data/${sample}/\n",
    "    python demultiplex.py \\\n",
    "    ${sample}.tsv \\\n",
    "    ../Fastq/${sample}_S${i}_L001_R1_001.fastq.gz ../Fastq/${sample}_S${i}_L001_R2_001.fastq.gz \\\n",
    "    ../raw_data/${sample}/\n",
    "    i=$((i+1))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test=open('EA01.tsv','r')\n",
    "for sample in sample_test:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('EA01.tsv','r')\n",
    "#sample_data = {}\n",
    "test=open('EA01.txt','w+')\n",
    "for l in fh:\n",
    "    #print(l)\n",
    "    cols = l.strip().split(\"\\t\")\n",
    "    sample = cols[1]\n",
    "    bcs = cols[2].split(\":\")\n",
    "    #sample_data[sample] = {'count': 0, 'bcs':[], 'seqs':{ 'R1': [], 'R2': []}}\n",
    "    #sample_data[sample]['bcs'] = bcs\n",
    "    test.write('%s\\t%s\\t%s\\n' %(sample,bcs[0],bcs[1]))\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#files=$(ls -1 ../Fastq | grep _R1 | cut -d'_' -f1)\n",
    "files='EA01'\n",
    "i=1\n",
    "for sample in $files\n",
    "do\n",
    "    mkdir ../raw_data/EA0100/\n",
    "    python demultiplex_obi.py \\\n",
    "    EA0100.tsv \\\n",
    "    ../Fastq/${sample}_S${i}_L001_R1_001.fastq.gz ../Fastq/${sample}_S${i}_L001_R2_001.fastq.gz \\\n",
    "    ../raw_data/EA0100/\n",
    "    i=$((i+1))\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordit='GAATTCGTGCTCACTGGGATTAGATACCCCACTATGCATAGCATAAATTTTGATAAAAATATACAATTTTATCCGCCAGGGAACTACAAGCATCAGCTTAAAACCCAAAGGACTTGGCGGTGCTTCAGACCCACCTAGAGGAGCCTGTTCTAGAGCACGAGGCT'\n",
    "#recordit=(in_seqs)[1]\n",
    "bc='GCGACGTG'\n",
    "#recordit=(in_seqs[1])\n",
    "if regex.search('('+bc+'){e<='+mm+'}',str(record.seq)[:30]):\n",
    "    print('fish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_seqs[1]\n",
    "str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "#from Bio import SeqIO\n",
    "import regex\n",
    "\n",
    "sample='BLEL01'\n",
    "mm='1'\n",
    "bc='ACACACAC'\n",
    "\n",
    "fastq=open(sample+'.fastq','w') #open up file named as sample\n",
    "\n",
    "sequences=[]\n",
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fastq\"):\n",
    "        #if regex.search('('+bc+'){e<='+mm+'}',str(record.seq)[:30]):\n",
    "        if regex.search('('+bc+'){e<=0}',str(record.seq)[:30]):\n",
    "            sequences.append(record)\n",
    "SeqIO.write(sequences,fastq,'fastq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###GOOD BIT###\n",
    "\n",
    "import gzip\n",
    "import regex\n",
    "\n",
    "sample='BLEL01'\n",
    "mm='1'\n",
    "bc='ACACACAC'\n",
    "\n",
    "fastq=open(sample+'.fastq','w+') #open up file named as sample\n",
    "\n",
    "sequences=[]\n",
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as handle:\n",
    "    for line in handle:\n",
    "        line.strip()\n",
    "        if regex.search('('+bc+'){e<='+mm+'}',str(record.seq)[:30]):\n",
    "        #if regex.search('('+bc+'){e<=0}',str(line)[:15]):\n",
    "        #if bc in str(line)[:30]:\n",
    "            #print(line)\n",
    "            fastq.write('%s' %(line))\n",
    "\n",
    "            #sequences.append(record)\n",
    "#SeqIO.write(sequences,fastq,'fastq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###GOOD BIT REVISITED###\n",
    "\n",
    "import gzip\n",
    "import regex\n",
    "\n",
    "sample='BLEL01'\n",
    "mm='1'\n",
    "bc='ACACACAC'\n",
    "\n",
    "fastq=open(sample+'.fastq','w+') #open up file named as sample\n",
    "\n",
    "sequences=[]\n",
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as handle:\n",
    "    for line in handle:\n",
    "        line.strip()\n",
    "        #if regex.search('('+bc+'){e<='+mm+'}',str(record.seq)[:30]):\n",
    "        #if regex.search('('+bc+'){e<=0}',str(line)[:30]):\n",
    "        if bc in str(line)[:30]:\n",
    "            #print(line)\n",
    "            fastq.write('%s' %(line.split(bc,1)[1]))\n",
    "\n",
    "            #sequences.append(record)\n",
    "#SeqIO.write(sequences,fastq,'fastq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###GOOD BIT WITH SEQIO###\n",
    "\n",
    "import gzip\n",
    "import regex\n",
    "from Bio import SeqIO\n",
    "\n",
    "sample='BLEL01'\n",
    "mm='1'\n",
    "bc='ACACACAC'\n",
    "\n",
    "fastq=open(sample+'.fastq','w+') #open up file named as sample\n",
    "\n",
    "sequences=[]\n",
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','r') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fastq\"):\n",
    "        #if regex.search('('+bc+'){e<='+mm+'}',str(record.seq)[:30]):\n",
    "        if bc in str(record.seq)[:30]:\n",
    "            SeqIO.write(record,fastq,'fastq')\n",
    "            \n",
    "            \n",
    "            #sequences.append(record)\n",
    "#SeqIO.write(sequences,fastq,'fastq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open ('testing.txt','r') as test:\n",
    "with open ('EAXX.tsv','w+') as liff:\n",
    "    testing=([line.strip() for line in open('testing.txt')])\n",
    "    for test in testing:\n",
    "        for test2 in testing:\n",
    "            #print('12S-fish\\tN\\t%s\\t%s\\tACTGGGATTAGATACCCC\\tTAGAACAGGCTCCTCTAG\\tF\\t@' %(test,test2))\n",
    "            liff.write('12S-fish\\tN\\t%s:%s\\tACTGGGATTAGATACCCC\\tTAGAACAGGCTCCTCTAG\\tF\\t@\\n' %(test,test2))\n",
    "\n",
    "    #print(test)\n",
    "\n",
    "\n",
    "#'12S-fish\\t%s\\t%S\\t%s\\tACTGGGATTAGATACCCC\\tTAGAACAGGCTCCTCTAG\\tF\\t@' %(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as handle:\n",
    "    handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample='BLEL01'\n",
    "mm='1'\n",
    "bc='ACACACAC'\n",
    "\n",
    "fastq=open(sample+'.fastq','w+') #open up file named as sample\n",
    "\n",
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as f1:\n",
    "    my_file = f1.readlines()\n",
    "    for i,line in enumerate(my_file):\n",
    "            if bc in line:\n",
    "                #print(file[i-4])\n",
    "                fastq.write('%s\\n' %(f1[i-4]))\n",
    "\n",
    "        #print file[i-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../Fastq/EA01_S1_L001_R1_001.fastq.gz','rt') as f1:\n",
    "    with gzip.open('../Fastq/EA01_S1_L001_R2_001.fastq.gz','rt') as f2:\n",
    "        lines = []\n",
    "        line = f1.readline()\n",
    "        if line.strip() == \"\":\n",
    "            break\n",
    "        lines.append(line.strip())\n",
    "\n",
    "        for i in range(3):\n",
    "            lines.append(f1.readline().strip())\n",
    "\n",
    "        for i in range(4):\n",
    "            lines.append(f2.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wc -l BLEL01.fastq\n",
    "\n",
    "wc -l ../raw_data/EA01/BLEL01.R1.fastq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(f, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "if regex.search('(test){e<=1}', '123 taast'):\n",
    "    print('fish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "files=$(ls -1 ../Fastq | grep _R1 | cut -d'_' -f1)\n",
    "i=1\n",
    "for sample in $files\n",
    "do\n",
    "    echo $i\n",
    "    i=$((i+1))\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
