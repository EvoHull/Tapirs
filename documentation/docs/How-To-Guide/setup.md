
!!! warning "install first then setup"
    These instructions are to set up Tapirs for your experiment after [installation](installation.md) has been carried out.

# CONFIG FILES
The `config.yaml` file contains settings for the workflow's operation. In an ideal experiment you would never have to alter any of the snakemake workflow code, only set up a configuration text file. Most of the settings in `config.yaml` have reasonable default values, but some may require your input. Open `config.yaml` in a text editor.

1. set a name for your experiment (default=expt_name)
2. set the directory containing your **demultiplexed** fastq.gz data (default=data/01_demultiplexed)
3. check the locations of your reference sequence databases are correct and amend if they are elsewhere. Defaults are:
    - `data/databases/blast`
    - `data/databases/kraken2`
    - `data/databases/taxonomy`
    - `data/databases/sintax`

In addition you may wish to fine-tune the analysis parameters of the programs. These parameters have reasonable defaults and changing them is not compulsory (unlike the options above, where you _must_ identify your data).

- set fastp parameters for quality control and read merging
- set blast parameters
- set MLCA parameters

# DATA

The `/data` directory must contain 2 subdirectories `/01_demultiplexed` `/databases`

## 01_demultiplexed
The start point of this workflows is demultiplexed fastq.gz sequence files in the data/01_demultiplexed directory. There are many ways to produce these files, and your sequencing machine or sequencing centre will most likely return this as the default data.

It is essential for reproducibility that this starting data is kept together with the experiment. If size prohibits its inclusion then archive it publicly and include the doi into the experimental record.

!!! tip "tip: exclude data directory from version control"
    Remember that if you are wisely keeping your analysis under git version control, then you can exclude very large data files from syncing to the web by including the data directory in your .gitignore file. It is essential however that you make other arrangements for both backing up and publishing the data.

### libraries and samples lists
Rather than implement a complex set of wildcards the recommended approach for snakemake is to create textual lists (.tsv files) of the sequencing metadata [Note1]. These lists can of course be generated by a script, but importantly this allows quality control and human intervention in determining what samples are analysed in each run. We then use the powerful Pandas data analysis library to read information from each and guide the workflow over the data.

!!! Note "Note 1: samples, libraries, and units .tsv"
    The naming of the files differs between biological disciplines. In our work a library often represents a physical location ("Lake Windermere") and a sample represents a physical unit taken for DNA extraction ("water-sample-12"). In other disciplines the meaning of "sample" may differ slightly.

Create two text files `libraries.tsv` and `samples.tsv` each using tab separated columns. Place these in the data folder at the top level. You should make sure that the `config.yaml` correctly points at these files.

## Databases
### Kraken2
In order to run a Kraken analysis you will need to create a Kraken database for the program to search your query sequences against. These databases can be large and require a lot of RAM and time to build them. They only need to be made once however and then all subsequent analyses can be performed against the same database. If you are building a custom database from a few thousand sequences then database construction will likely be quick.

Creating a local Kraken2 database for Tapirs requires a fasta input file containing all reference sequences.

Database creation has 3 steps:
1. Download taxonomy:
`kraken2-build --download-taxonomy --db fish_kraken --threads 6`
2. Add sequences to library:
`kraken2-build --add-to-library databases/12s_verts.fasta --no-masking --db fish_kraken --threads 6`
the `--no-masking` flag improved accuracy for short reads
3. Build database:
`kraken2-build --build --minimizer-spaces 1 --kmer-len 31 --db fish_kraken --threads 6`
it is important to have some minimizer-spaces in lmers, having 1 makes for more accurate taxonomic assignment. Having kmer same length as lmer for shorter reads makes for more accurate taxonomic assignment

See the [Kraken Tutorial](../Tutorials/kraken_tutorial.md) and the [Kraken2 manual](https://ccb.jhu.edu/software/kraken2/index.shtml?t=manual) for information on building Kraken databases.

It is essential for reproducibility that you publicly archive your database at the end of the experiment. [Zenodo.org](zenodo.org) is a suitable location.

### blast
You will need to build a blastn database from a collection of fasta files. Information on this can be found at the NCBI site [Blast help pages](https://www.ncbi.nlm.nih.gov/books/NBK279680/).

You will require:
* Fasta input file containing all reference sequences
* Accession to taxid map. See [NCBI blast instructions](https://www.ncbi.nlm.nih.gov/books/NBK279688/) for more details.

!!! note "create a blast database"
    If you have a single fasta format file (allseqs.fas) containing all the sequences to be included in the database, then you could create a blast database with the command:

    `makeblastdb -in blast_db/allseqs.fasta -input_type fasta -dbtype nucl \
    -parse_seqids -taxid_map blast_db/tax_map.txt -out blast_db/allseqs`

See the [Blast Tutorial](../Tutorials/blast_tutorial.md) for more detailed help

It is essential for reproducibility that you publicly archive your database at the end of the experiment. [Zenodo.org](zenodo.org) is a suitable location.

### taxonomy database
Several programs require the NCBI taxonomy database in order to carry out taxonomic assignment.

### SINTAX
SINTAX (Edgar 2016) is a kmer similarity approach to taxonomic ID that classifies and gives confidence estimates on the classification. It requires a database (fasta, fastq, or udb database format) in the data/databsaes/sintax directory.

A sintax database is created using specific taxonomic information in the header line of the fasta file. We provide a script to help with this formatting.

### krona
Krona should self-install from the snakemake rule supplied.

# DRY RUN TAPIRS
Make sure you are in the directory containing the snakefile then type `snakefile --use-conda -npr`  or `snakemake -s snakefile --use-conda --printshellcmds -n` to dry-run the workflow.

If all has gone well Snakemake will report the jobs it needs to perform without any complaint. If not (as is common in most experiments) you will need to diagnose and fix any minor issues. Some errors are only detected in the real run, not the dry run, and they often concern the format of data files, as these have not been checked by a dry run.

# RUN TAPIRS
Run Tapirs with either the `snakemake --use-conda` or `snakemake -s snakefile --use-conda --printshellcmds` command

Tapirs should now run, processing the data from 01_demultiplexed, assigning taxonomy using blast, kraken2 and sintax, writing reports, and creating html displays of the taxonomic composition of each sample using krona.

<hr>
**REFERENCES**

R.C. Edgar (2016), SINTAX: a simple non-Bayesian taxonomy classifier for 16S and ITS sequences, [https://doi.org/10.1101/074161](https://doi.org/10.1101/074161)
