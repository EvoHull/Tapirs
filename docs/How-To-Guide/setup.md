
!!! warning "install first then setup"
    These instructions are to set up Tapirs for your experiment after [installation](installation.md) has been carried out.

# CONFIG FILES
The `config.yaml` file contains settings for the workflow's operation. In an ideal experiment you would never have to alter any of the snakemake workflow code, only set up a configuration text file. Most of the settings in `config.yaml` have reasonable default values, but some may require your input. Open `config.yaml` in a text editor.

1. set a name for your experiment (default=expt_name)
2. set the directory containing your **demultiplexed** fastq.gz data (default=data/01_demultiplexed)
3. check the locations of your reference sequence databases are correct and amend if they are elsewhere. Defaults are:
    - `data/databases/blast`
    - `data/databases/kraken2`
    - `data/databases/taxonomy`
    - `data/databases/sintax`

In addition you may wish to fine-tune the analysis parameters of the programs. These parameters have reasonable defaults and changing them is not compulsory (unlike the options above, where you _must_ identify your data).

- set fastp parameters for quality control and read merging
- set blast parameters
- set MLCA parameters

# DATA

The `data/` directory must contain 2 subdirectories `01_demultiplexed/` `databases/`

## 01_demultiplexed
The start point of this workflows is demultiplexed fastq.gz sequence files in the data/01_demultiplexed directory. There are many ways to produce these files, and your sequencing machine or sequencing centre will most likely return this as the default data.

It is essential for reproducibility that this starting data is kept together with the experiment. If size prohibits its inclusion then archive it publicly and include the doi into the experimental record.

!!! tip "tip: exclude data directory from version control"
    Remember that if you are wisely keeping your analysis under git version control, then you can exclude very large data files from syncing to the web by including the data directory in your .gitignore file. It is essential however that you make other arrangements for both backing up and publishing the data.

To facilitate iteration, the input files must follow the structure of `yourlibrary/yoursample.R*.fastq.gz`, the full path being `Tapirs/data/01_demultiplexed/yourlibrary/yoursample.R*.fastq.gz`. The * asterisk stands for the read number, ie R1 or R2.

### libraries and samples lists
Rather than implement a complex set of wildcards the recommended approach for snakemake is to create textual lists (.tsv files) of the sequencing metadata [Note1]. These lists can of course be generated by a script, but importantly this allows quality control and human intervention in determining what samples are analysed in each run. We then use the powerful Pandas data analysis library to read information from each .tsv file and guide the workflow over the data.

!!! Note "Note 1: samples, libraries, and units .tsv"
    The naming of the files differs between biological disciplines. In our work a library often represents a physical location ("Lake Windermere") and a sample represents a physical unit taken for DNA extraction ("water-sample-12"). In other disciplines the meaning of "sample" may differ slightly.

Tapirs contains a custom bash script to create two text files `libraries.tsv` and `samples.tsv` each containing a list of all library and sample names respectively, performed with:
`bash scripts/wildcarding.sh`

You should make sure that the `config.yaml` correctly points at these files. These will need removing and regenerating if libraries or samples change input.

## Databases
### Kraken2
In order to run a Kraken analysis you will need to create a Kraken database for the program to search your query sequences against. These databases can be large and require a lot of RAM and time to build them. They only need to be made once however and then all subsequent analyses can be performed against the same database. If you are building a custom database from a few thousand sequences then database construction will likely be quick.

Creating a local Kraken2 database for Tapirs requires a fasta input file containing all reference sequences.

Database creation has 3 steps:

1. Download taxonomy:
`kraken2-build --download-taxonomy --db fish_kraken --threads 6`
2. Add sequences to library:
`kraken2-build --add-to-library databases/12s_verts.fasta --no-masking --db fish_kraken --threads 6`
the `--no-masking` flag improved accuracy for short reads
3. Build database:
`kraken2-build --build --minimizer-spaces 1 --kmer-len 31 --db fish_kraken --threads 6`
it is important to have some minimizer-spaces in lmers, having 1 makes for more accurate taxonomic assignment. Having kmer same length as lmer for shorter reads makes for more accurate taxonomic assignment

`fish_kraken` and `12s_verts.fasta` are our experiment-specific names for our data, you will choose different names.

See the [Kraken Tutorial](../Tutorials/kraken_tutorial.md) and the [Kraken2 manual](https://ccb.jhu.edu/software/kraken2/index.shtml?t=manual) for information on building Kraken databases.

It is essential for reproducibility that you publicly archive your database at the end of the experiment. [Zenodo.org](https://zenodo.org) is a suitable location. If your database is too large to database easily, consider making it from scripts in a reproducible manner instead and then archiving those scripts. Don't forget to include the international sequence database **version** from which your scripts harvested the sequences.

### blast
You will need to build a blastn database from a collection of fasta files. Information on this can be found at the NCBI site [Blast help pages](https://www.ncbi.nlm.nih.gov/books/NBK279680/).

You will require:

* Fasta input file containing all reference sequences
* Accession to taxid map. See [NCBI blast instructions](https://www.ncbi.nlm.nih.gov/books/NBK279688/) for more details.

!!! note "create a blast database"
    If you have a single fasta format file (allseqs.fas) containing all the sequences to be included in the database, then you could create a blast database with the command:

    `makeblastdb -in blast_db/allseqs.fasta -input_type fasta -dbtype nucl \
    -parse_seqids -taxid_map blast_db/tax_map.txt -out blast_db/allseqs`

See the [Blast Tutorial](../Tutorials/blast_tutorial.md) for more detailed help

It is essential for reproducibility that you publicly archive your database at the end of the experiment. [Zenodo.org](https://zenodo.org) is a suitable location.

### taxonomy database
Several programs require the NCBI taxonomy database in order to carry out taxonomic assignment.

### SINTAX
SINTAX (Edgar 2016) is a kmer similarity approach to taxonomic ID that classifies and gives confidence estimates on the classification. It requires a database (fasta, fastq, or udb database format) in the data/databsaes/sintax directory.

A sintax database is created using specific taxonomic information in the header line of the fasta file. We hope soon to provide a script to help with this formatting.

### krona
Krona should self-install it's taxonomy database from the snakemake rule supplied.

# DRY RUN TAPIRS
Make sure you are in the directory containing the snakefile then type `snakefile --use-conda -npr`  or `snakemake -s snakefile --use-conda --printshellcmds -n -k` to dry-run the workflow.

If all has gone well Snakemake will report the jobs it needs to perform without any complaint. If not (as is common in most experiments) you will need to diagnose and fix any minor issues. Some errors are only detected in the real run, not the dry run, and they often concern the format of data files, as these have not been checked by a dry run.

# RUN TAPIRS
Run Tapirs with either the `snakemake --use-conda` or `snakemake -s snakefile --use-conda --printshellcmds` command

Tapirs should now run, processing the data from 01_demultiplexed, assigning taxonomy using blast, kraken2 and sintax, writing reports, and creating html displays of the taxonomic composition of each sample using krona.

# EXCLUDE ANALYSES
If you wish to run Tapirs without invoking one of analysis programs (eg SINTAX or Kraken2 or blast) then you can comment out the line that calls them in the snakefile. Towards the bottom of the snakefile in the top level directory you will see a line such as:

`include: "rules/sintax.smk"`

to remove sintax comment this line out by prefixing with a hash # then save and rerun snakemake.

# REMOVING FILES FROM PREVIOUS RUNS
Snakemake can clean up files it as previously created. This is useful if you have reports and intermediate results from previous runs that you wish to remove before a new run. The Snakemake docs have a [FAQ on cleaning files](https://snakemake.readthedocs.io/en/stable/project_info/faq.html#how-do-i-remove-all-files-created-by-snakemake-i-e-like-make-clean), in short though try `snakemake some_target --delete-all-output` and add `--dry-run` the first time to check what will be removed before you do it.

<hr>
**REFERENCES**



Altschul, S. F. et al. (1990) ‘Basic local alignment search tool’, Journal of molecular biology, 215(3), pp. 403–410. [doi: 10.1016/S0022-2836(05)80360-2](https://doi.org/10.1016/S0022-2836(05)80360-2)

Chen, S. et al. (2018) ‘fastp: an ultra-fast all-in-one FASTQ preprocessor’, Bioinformatics . Oxford University Press, 34(17), pp. i884–i890. [doi: 10.1093/bioinformatics/bty560](https://doi.org/10.1093/bioinformatics/bty560)

Daniel McDonald, Jose C. Clemente, Justin Kuczynski, Jai Ram Rideout, Jesse Stombaugh, Doug Wendel, Andreas Wilke, Susan Huse, John Hufnagle, Folker Meyer, Rob Knight, and J. Gregory Caporaso. The Biological Observation Matrix (BIOM) format or: how I learned to stop worrying and love the ome-ome. GigaScience 2012, 1:7. [doi:10.1186/2047-217X-1-7](https://doi.org/10.1186/2047-217X-1-7)

Ondov, B. D., Bergman, N. H. and Phillippy, A. M. (2011) ‘Interactive metagenomic visualization in a Web browser’, BMC bioinformatics, 12, p. 385. [doi: 10.1186/1471-2105-12-385](https://doi.org/10.1186/1471-2105-12-385)

Rognes, T. et al. (2016) ‘VSEARCH: a versatile open source tool for metagenomics’, PeerJ, 4, p. e2584. [doi: 10.7717/peerj.2584]

Wood, D. E., Lu, J. and Langmead, B. (2019) ‘Improved metagenomic analysis with Kraken 2’, Genome biology, 20(1), p. 257. [doi: 10.1186/s13059-019-1891-0](https://doi.org/10.1186/s13059-019-1891-0)

R.C. Edgar (2016), SINTAX: a simple non-Bayesian taxonomy classifier for 16S and ITS sequences, [https://doi.org/10.1101/074161](https://doi.org/10.1101/074161)
